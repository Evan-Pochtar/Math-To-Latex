{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["-Raw2ptFPaNR"],"machine_shape":"hm","gpuType":"L4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Install Necessary Libraries for the Project"],"metadata":{"id":"-Raw2ptFPaNR"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6CiOGaCTPRPw","outputId":"5db28de0-2dbc-44cc-ad46-0f34a64bb755","executionInfo":{"status":"ok","timestamp":1744076029921,"user_tz":300,"elapsed":75529,"user":{"displayName":"Ajitesh Parthasarathy","userId":"10718185110510952821"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Collecting datasets\n","  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n","Collecting trl\n","  Downloading trl-0.16.1-py3-none-any.whl.metadata (12 kB)\n","Collecting jiwer\n","  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec (from torch)\n","  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (13.9.4)\n","Requirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.50.3)\n","Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n","Collecting rapidfuzz>=3.9.7 (from jiwer)\n","  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (0.21.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trl-0.16.1-py3-none-any.whl (336 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n","Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, rapidfuzz, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jiwer, nvidia-cusolver-cu12, datasets, trl\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.3.2\n","    Uninstalling fsspec-2025.3.2:\n","      Successfully uninstalled fsspec-2025.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 jiwer-3.1.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 rapidfuzz-3.13.0 trl-0.16.1 xxhash-3.5.0\n"]}],"source":["!pip install torch datasets accelerate trl jiwer"]},{"cell_type":"markdown","source":["# Load and Prepare the Dataset"],"metadata":{"id":"lEVO20NNMhSh"}},{"cell_type":"code","source":["import os\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader, random_split\n","import torchvision.transforms as transforms  # Add this import\n","import random\n","import torch\n","# Define the Dataset with transform\n","class HandwrittenMathDataset(Dataset):\n","    def __init__(self, image_directory, labels_file, transform=None):\n","        self.image_paths = []\n","        self.latex_sequences = []\n","        self.transform = transform  # Store the transform\n","\n","        with open(labels_file, 'r') as f:\n","            for line in f:\n","                line = line.strip()\n","                if not line:\n","                    continue\n","                parts = line.split('\\t')\n","                if len(parts) == 2:\n","                    image_filename, latex_seq = parts\n","                    image_path = os.path.join(image_directory, image_filename)\n","                    if os.path.exists(image_path):\n","                        self.image_paths.append(image_path)\n","                        self.latex_sequences.append(latex_seq)\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        image_path = self.image_paths[idx]\n","        image = Image.open(image_path).convert('L')  # PIL Image\n","\n","        # Apply transform if defined\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        latex_seq = self.latex_sequences[idx]\n","        return image, latex_seq\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","folder_path = '/content/drive/MyDrive/3312_images/'\n","\n","# Define the transform\n","transform = transforms.Compose([\n","    transforms.ToTensor()  # Convert PIL Image to PyTorch Tensor\n","])\n","\n","# Create dataset with transform\n","dataset = HandwrittenMathDataset(\n","    image_directory=folder_path + \"synthetic_images\",\n","    labels_file=folder_path + \"synthetic_labels.txt\",\n","    transform=transform  # Add the transform here\n",")\n","\n","# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","# print(f\"Dataset size: {len(train_dataset)}\")\n","# print(train_dataset.__getitem__(0))\n","\n","def create_train_test_split(dataset, test_size=0.2, random_state=42):\n","    \"\"\"\n","    Split the dataset into training and testing sets\n","\n","    Args:\n","        dataset (ImageTextDataset): The dataset to split\n","        test_size (float): Proportion of the dataset to include in the test split\n","        random_state (int): Random seed for reproducibility\n","\n","    Returns:\n","        tuple: (train_dataset, test_dataset)\n","    \"\"\"\n","    # Method 1: Using PyTorch's random_split\n","    train_size = int((1 - test_size) * len(dataset))\n","    test_size = len(dataset) - train_size\n","\n","    train_dataset, test_dataset = random_split(\n","        dataset,\n","        [train_size, test_size],\n","        generator=torch.Generator().manual_seed(random_state)\n","    )\n","\n","    return train_dataset, test_dataset\n","train_dataset, test_dataset = create_train_test_split(dataset, test_size=0.2)\n","\n","# Create dataloaders\n","batch_size = 16\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size)"],"metadata":{"id":"0A9O9lUCM83_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745188969544,"user_tz":300,"elapsed":49283,"user":{"displayName":"Ajitesh Parthasarathy","userId":"10718185110510952821"}},"outputId":"57a3c87c-525f-41c3-c2ee-20657b3d6a05"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from collections import defaultdict\n","def build_vocab(labels_file, vocab_size=500):\n","    # Collect all characters\n","    all_chars = defaultdict(int)\n","    special_tokens = ['<start>', '<end>', '<pad>']\n","    with open(labels_file, 'r') as f:\n","        for line in f:\n","            line = line.strip()\n","            if line:\n","                split_line = line.split('\\t')\n","                if(len(split_line) > 2):\n","                    latex = \"\\t\".join(split_line[1:len(split_line)])\n","                else:\n","                    latex = split_line[1]\n","                for char in latex:\n","                    all_chars[char] += 1\n","    # Sort characters by frequency\n","    sorted_chars = sorted(all_chars.items(), key=lambda x: x[1], reverse=True)\n","    # Assign indices: 0 for <pad>, 1 for <start>, 2 for <end>, then others\n","    vocab = {'<pad>': 0, '<start>': 1, '<end>': 2}\n","    idx = 3\n","    for char, _ in sorted_chars:\n","        if char not in vocab and idx < vocab_size:\n","            vocab[char] = idx\n","            idx += 1\n","    return vocab\n","folder_path = '/content/drive/MyDrive/3312_images/'\n","labels_file = folder_path + \"synthetic_labels.txt\"\n","vocab = build_vocab(labels_file, vocab_size=500)\n","vocab_size = len(vocab)\n","print(f\"Vocabulary size: {vocab_size}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oVZXX3hVAoAw","executionInfo":{"status":"ok","timestamp":1745188989567,"user_tz":300,"elapsed":23,"user":{"displayName":"Ajitesh Parthasarathy","userId":"10718185110510952821"}},"outputId":"755d4c24-c18c-48b6-a777-342374d67a06"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary size: 95\n"]}]},{"cell_type":"code","source":["def string_to_tensor(string_list, vocab):\n","    max_length = 0\n","    all_indices = []\n","    for string in string_list:\n","        # Convert characters to indices, using vocab.get(char, 0) for unknowns (0 is <pad>)\n","        indices = [vocab.get('<start>')] + [vocab.get(char, 0) for char in string] + [vocab.get('<end>')]\n","        all_indices.append(indices)\n","        max_length = max(max_length, len(indices))\n","    # Pad sequences to max_length\n","    padded_indices = [\n","        seq + [vocab['<pad>']] * (max_length - len(seq)) for seq in all_indices\n","    ]\n","    tensor = torch.tensor(padded_indices, dtype=torch.long).t()  # [seq_len, batch_size]\n","    return tensor\n","\n","def tensor_to_string(tensor, vocab):\n","    \"\"\"Convert a tensor of token indices to strings\"\"\"\n","    # Get index-to-token mapping (reverse of the vocabulary)\n","    idx_to_token = {idx: token for token, idx in vocab.items()}\n","\n","    # If tensor is [T, B], convert to [B, T] for batch processing\n","    if tensor.dim() == 2:\n","        tensor = tensor.transpose(0, 1)\n","\n","    batch_texts = []\n","    for sequence in tensor:\n","        tokens = [idx_to_token.get(idx.item(), \"\") for idx in sequence]\n","        # Stop at end-of-sequence token if present\n","        if \"<eos>\" in tokens:\n","            tokens = tokens[:tokens.index(\"<eos>\")]\n","        text = \"\".join(tokens)\n","        batch_texts.append(text)\n","\n","    return batch_texts"],"metadata":{"id":"415y0hiC9W4W","executionInfo":{"status":"ok","timestamp":1745188992746,"user_tz":300,"elapsed":10,"user":{"displayName":"Ajitesh Parthasarathy","userId":"10718185110510952821"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Project Code"],"metadata":{"id":"HYI3-SoWPt7p"}},{"cell_type":"markdown","source":["Step 1.) CNN or Transformer based Image -> Latex conversion"],"metadata":{"id":"xIeaRfRanCuG"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","# Define the Encoder (CNN)\n","class CNNEncoder(nn.Module):\n","    def __init__(self, encoded_image_size=14):\n","        super(CNNEncoder, self).__init__()\n","        # TODO: Should we replace this with a pretrained model instead?\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n","        self.encoded_image_size = encoded_image_size\n","\n","    def forward(self, images):\n","        x = F.relu(self.conv1(images))   # [B, 32, H, W]\n","        x = self.pool(x)                 # Downsample\n","        x = F.relu(self.conv2(x))        # [B, 64, H/2, W/2]\n","        x = self.pool(x)                 # Downsample further\n","        print(x.shape)\n","        batch_size, channels, height, width = x.size()\n","        x = x.view(batch_size, channels, -1)  # Flatten spatial dimensions: [B, C, N]\n","        x = x.permute(0, 2, 1)           # [B, N, C] for the transformer encoder input\n","        return x\n","\n","# Define the Decoder (Transformer)\n","class TransformerDecoder(nn.Module):\n","    def __init__(self, vocab_size, d_model=256, num_layers=2, nhead=8, dropout=0.1, max_seq_length=100):\n","        super(TransformerDecoder, self).__init__()\n","        self.d_model = d_model\n","        self.embedding = nn.Embedding(vocab_size, d_model)\n","        self.pos_embedding = nn.Embedding(max_seq_length, d_model)\n","        decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, dropout=dropout)\n","        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n","        self.fc_out = nn.Linear(d_model, vocab_size)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, tgt, memory):\n","        # tgt: [T, B] and memory: [S, B, E]\n","        T, B = tgt.size()\n","        positions = torch.arange(0, T).unsqueeze(1).expand(T, B).to(tgt.device)\n","        positions = positions.clamp(0, self.pos_embedding.num_embeddings - 1)  # Clamp positions\n","        tgt_emb = self.embedding(tgt) + self.pos_embedding(positions)\n","        tgt_emb = self.dropout(tgt_emb)\n","        # Generate a mask to prevent attention to future tokens\n","        tgt_mask = nn.Transformer.generate_square_subsequent_mask(T).to(tgt.device)\n","        output = self.transformer_decoder(tgt_emb, memory, tgt_mask=tgt_mask)\n","        output = self.fc_out(output)\n","        return output\n","\n","# Combine Encoder and Decoder into one Model\n","class HandwrittenMathToLatexModel(nn.Module):\n","    def __init__(self, vocab_size, d_model=256):\n","        super(HandwrittenMathToLatexModel, self).__init__()\n","        self.encoder = CNNEncoder()\n","        self.decoder = TransformerDecoder(vocab_size=vocab_size, d_model=d_model)\n","        # Project encoder output to match decoder d_model if needed\n","        self.enc_to_dec = nn.Linear(64, d_model)\n","\n","    def forward(self, images, tgt_seq):\n","        # images: [B, 1, H, W]\n","        # tgt_seq: [T, B]\n","        enc_out = self.encoder(images)  # [B, N, 64]\n","        enc_out = self.enc_to_dec(enc_out)  # [B, N, d_model]\n","        # Transformer expects: [S, B, E]\n","        enc_out = enc_out.permute(1, 0, 2)\n","        output = self.decoder(tgt_seq, enc_out)  # [T, B, vocab_size]\n","        return output\n","\n","# Training Loop\n","def train(model, dataloader, criterion, optimizer, device):\n","    model.train()\n","    running_loss = 0.0\n","    for images, target_seq in dataloader:\n","        images = images.to(device)\n","        # Get the tensor from the tuple returned by string_to_tensor\n","        target_seq = string_to_tensor(target_seq, vocab).to(device)\n","        target_seq = target_seq.to(device)\n","        # Assume target_seq is size [T, B]\n","        optimizer.zero_grad()\n","        # Shift target sequence for teacher forcing\n","        input_seq = target_seq[:-1, :]\n","        output = model(images, input_seq)\n","        # Compute loss between output and target_seq[1:,:]\n","        loss = criterion(output.reshape(-1, output.shape[-1]), target_seq[1:, :].reshape(-1))\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","    return running_loss / len(dataloader)\n","def test(model, dataloader, criterion, device):\n","    model.eval()\n","    running_loss = 0.0\n","    with torch.no_grad():\n","        for images, target_seq in dataloader:\n","            images = images.to(device)\n","            target_seq = string_to_tensor(target_seq, vocab).to(device)\n","            # Shift target sequence for decoder input (same as in training)\n","            input_seq = target_seq[:-1, :]\n","            output = model(images, input_seq)\n","\n","            # _, predicted_indices = torch.max(output, dim=2)\n","            # predicted_text = tensor_to_string(predicted_indices, vocab)\n","            # print(f\"Predicted: {predicted_text}\")\n","\n","            # Calculate loss against the full target sequence (offset by 1)\n","            loss = criterion(output.reshape(-1, output.shape[-1]),\n","                            target_seq[1:, :].reshape(-1))\n","            running_loss += loss.item()\n","    return running_loss / len(dataloader)\n","\n","\n","# Initialize Hyperparameters\n","batch_size = 16\n","learning_rate = 1e-3\n","num_epochs = 10\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = HandwrittenMathToLatexModel(vocab_size=vocab_size).to(device)\n","criterion = nn.CrossEntropyLoss(ignore_index=0)  # Adjust ignore_index if needed (for padding)\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","for epoch in range(num_epochs):\n","    train_loss = train(model, train_loader, criterion, optimizer, device)\n","    test_loss = test(model, test_loader, criterion, device)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n"],"metadata":{"id":"fzKwW-RvPqI6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3034cb9d-33ee-498f-c576-e97eda4fffb4","executionInfo":{"status":"ok","timestamp":1745194078378,"user_tz":300,"elapsed":2633029,"user":{"displayName":"Ajitesh Parthasarathy","userId":"10718185110510952821"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([1, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([9, 64, 64, 64])\n","Epoch [1/10], Train Loss: 2.8276, Test Loss: 2.4973\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([1, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([9, 64, 64, 64])\n","Epoch [2/10], Train Loss: 2.3883, Test Loss: 2.1971\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([1, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([9, 64, 64, 64])\n","Epoch [3/10], Train Loss: 2.1384, Test Loss: 2.0303\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([1, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([9, 64, 64, 64])\n","Epoch [4/10], Train Loss: 1.9798, Test Loss: 1.9239\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([1, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([9, 64, 64, 64])\n","Epoch [5/10], Train Loss: 1.8570, Test Loss: 1.8794\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([1, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([9, 64, 64, 64])\n","Epoch [6/10], Train Loss: 1.7698, Test Loss: 1.7851\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([1, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([9, 64, 64, 64])\n","Epoch [7/10], Train Loss: 1.6868, Test Loss: 1.7892\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([1, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([9, 64, 64, 64])\n","Epoch [8/10], Train Loss: 1.6375, Test Loss: 1.7598\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([1, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([9, 64, 64, 64])\n","Epoch [9/10], Train Loss: 1.5793, Test Loss: 1.7466\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([1, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([16, 64, 64, 64])\n","torch.Size([9, 64, 64, 64])\n","Epoch [10/10], Train Loss: 1.5311, Test Loss: 1.7616\n"]}]},{"cell_type":"code","source":["import math\n","class ImprovedCNNEncoder(nn.Module):\n","    def __init__(self, encoded_image_size=14):\n","        super().__init__()\n","        self.cnn = nn.Sequential(\n","            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","\n","            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","\n","            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","\n","            nn.AdaptiveAvgPool2d((encoded_image_size, encoded_image_size))\n","        )\n","\n","    def forward(self, images):\n","        features = self.cnn(images)  # [B, 256, 14, 14]\n","        features = features.flatten(2).permute(0, 2, 1)  # [B, 196, 256]\n","        return features\n","\n","class ImprovedTransformerDecoder(nn.Module):\n","    def __init__(self, vocab_size, d_model=512, num_layers=4, nhead=8, dropout=0.2, max_seq_length=5000):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, d_model)\n","        self.pos_encoder = PositionalEncoding(d_model, dropout, max_len=max_seq_length)\n","        decoder_layer = nn.TransformerDecoderLayer(d_model, nhead, dim_feedforward=d_model*4, dropout=dropout)\n","        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers)\n","        self.fc_out = nn.Linear(d_model, vocab_size)\n","\n","    def forward(self, tgt, memory, tgt_mask=None):\n","        tgt_emb = self.embedding(tgt) * math.sqrt(self.embedding.embedding_dim)\n","        tgt_emb = self.pos_encoder(tgt_emb)\n","        output = self.decoder(tgt_emb, memory, tgt_mask=tgt_mask)\n","        return self.fc_out(output)\n","\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super().__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","        position = torch.arange(max_len).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n","        pe = torch.zeros(max_len, 1, d_model)\n","        pe[:, 0, 0::2] = torch.sin(position * div_term)\n","        pe[:, 0, 1::2] = torch.cos(position * div_term)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:x.size(0)]\n","        return self.dropout(x)\n","\n","\n","class ImprovedHandwrittenMathToLatexModel(nn.Module):\n","    def __init__(self, vocab_size, d_model=512):\n","        super().__init__()\n","        self.encoder = ImprovedCNNEncoder()\n","        self.decoder = ImprovedTransformerDecoder(vocab_size, d_model)\n","        self.enc_proj = nn.Linear(256, d_model)\n","\n","    def forward(self, images, tgt_seq):\n","        enc_out = self.encoder(images)  # [B, N, 256]\n","        enc_out = self.enc_proj(enc_out)  # [B, N, d_model]\n","        enc_out = enc_out.permute(1, 0, 2)  # [N, B, d_model]\n","        output = self.decoder(tgt_seq, enc_out)\n","        return output\n","\n","# Modify hyperparameters\n","d_model = 512\n","num_epochs = 10\n","batch_size = 16\n","learning_rate = 3e-4\n","weight_decay = 1e-5\n","\n","# Use learning rate scheduler\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = ImprovedHandwrittenMathToLatexModel(vocab_size=vocab_size).to(device)\n","optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate,\n","                                        steps_per_epoch=len(train_loader), epochs=num_epochs)\n","\n","# Add label smoothing\n","criterion = nn.CrossEntropyLoss(ignore_index=0, label_smoothing=0.1)\n","def train(model, dataloader, criterion, optimizer, device):\n","    model.train()\n","    running_loss = 0.0\n","    for images, target_seq in dataloader:\n","        images = images.to(device)\n","        # Get the tensor from the tuple returned by string_to_tensor\n","        target_seq = string_to_tensor(target_seq, vocab).to(device)\n","        target_seq = target_seq.to(device)\n","        # Assume target_seq is size [T, B]\n","        optimizer.zero_grad()\n","        # Shift target sequence for teacher forcing\n","        input_seq = target_seq[:-1, :]\n","        output = model(images, input_seq)\n","        # Compute loss between output and target_seq[1:,:]\n","        loss = criterion(output.reshape(-1, output.shape[-1]), target_seq[1:, :].reshape(-1))\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        running_loss += loss.item()\n","    return running_loss / len(dataloader)\n","def test(model, dataloader, criterion, device):\n","    model.eval()\n","    running_loss = 0.0\n","    with torch.no_grad():\n","        for images, target_seq in dataloader:\n","            images = images.to(device)\n","            target_seq = string_to_tensor(target_seq, vocab).to(device)\n","            # Shift target sequence for decoder input (same as in training)\n","            input_seq = target_seq[:-1, :]\n","            output = model(images, input_seq)\n","            # Calculate loss against the full target sequence (offset by 1)\n","            loss = criterion(output.reshape(-1, output.shape[-1]),\n","                            target_seq[1:, :].reshape(-1))\n","            running_loss += loss.item()\n","    return running_loss / len(dataloader)\n","\n","for epoch in range(num_epochs):\n","    train_loss = train(model, train_loader, criterion, optimizer, device)\n","    test_loss = test(model, test_loader, criterion, device)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GBBzVr3DIC-o","executionInfo":{"status":"ok","timestamp":1744249019697,"user_tz":300,"elapsed":2759856,"user":{"displayName":"Ajitesh Parthasarathy","userId":"10718185110510952821"}},"outputId":"1b96abbb-4848-4eee-d762-1ce0ff0b83ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 3.6705, Test Loss: 3.0987\n","Epoch [2/10], Train Loss: 2.9336, Test Loss: 2.7483\n","Epoch [3/10], Train Loss: 2.7144, Test Loss: 2.6744\n","Epoch [4/10], Train Loss: 2.5620, Test Loss: 2.5311\n","Epoch [5/10], Train Loss: 2.4619, Test Loss: 2.4439\n","Epoch [6/10], Train Loss: 2.3683, Test Loss: 2.3456\n","Epoch [7/10], Train Loss: 2.2839, Test Loss: 2.3125\n","Epoch [8/10], Train Loss: 2.2357, Test Loss: 2.2829\n","Epoch [9/10], Train Loss: 2.1945, Test Loss: 2.2683\n","Epoch [10/10], Train Loss: 2.1663, Test Loss: 2.2675\n"]}]},{"cell_type":"code","source":["# Define the Encoder (Transformer)\n","class TransformerEncoder(nn.Module):\n","    def __init__(self, d_model=256, nhead=8, num_encoder_layers=3, dim_feedforward=1024, dropout=0.1):\n","        super(TransformerEncoder, self).__init__()\n","        # Initial embedding layer to convert image patches to embeddings\n","        self.patch_embedding = nn.Conv2d(1, d_model, kernel_size=4, stride=4)\n","\n","        # Positional encoding for patches\n","        self.pos_embedding = nn.Parameter(torch.zeros(1, 4096, d_model))\n","\n","        # Transformer encoder layers\n","        encoder_layer = nn.TransformerEncoderLayer(\n","            d_model=d_model,\n","            nhead=nhead,\n","            dim_feedforward=dim_feedforward,\n","            dropout=dropout\n","        )\n","        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n","\n","        self.d_model = d_model\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, images):\n","        # images: [B, 1, H, W]\n","        batch_size = images.size(0)\n","\n","        # Create patch embeddings [B, d_model, h, w]\n","        x = self.patch_embedding(images)\n","\n","        # Reshape to [B, d_model, N] where N is number of patches\n","        h, w = x.shape[-2:]\n","        x = x.reshape(batch_size, self.d_model, h*w)\n","\n","        # Permute to [B, N, d_model] for transformer input\n","        x = x.permute(0, 2, 1)\n","\n","        # Add positional embeddings\n","        x = x + self.pos_embedding[:, :x.size(1), :]\n","\n","        # Apply dropout\n","        x = self.dropout(x)\n","\n","        # Transformer expects: [N, B, E]\n","        x = x.permute(1, 0, 2)\n","\n","        # Pass through transformer encoder\n","        memory = self.transformer_encoder(x)\n","\n","        return memory  # [N, B, E]\n","\n","# Define the Decoder (Transformer)\n","class TransformerDecoder(nn.Module):\n","    def __init__(self, vocab_size, d_model=256, num_layers=2, nhead=8, dropout=0.1, max_seq_length=100):\n","        super(TransformerDecoder, self).__init__()\n","        self.d_model = d_model\n","        self.embedding = nn.Embedding(vocab_size, d_model)\n","        self.pos_embedding = nn.Embedding(max_seq_length, d_model)\n","        decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, dropout=dropout)\n","        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n","        self.fc_out = nn.Linear(d_model, vocab_size)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, tgt, memory):\n","        # tgt: [T, B] and memory: [S, B, E]\n","        T, B = tgt.size()\n","        positions = torch.arange(0, T).unsqueeze(1).expand(T, B).to(tgt.device)\n","        positions = positions.clamp(0, self.pos_embedding.num_embeddings - 1)  # Clamp positions\n","        tgt_emb = self.embedding(tgt) + self.pos_embedding(positions)\n","        tgt_emb = self.dropout(tgt_emb)\n","        # Generate a mask to prevent attention to future tokens\n","        tgt_mask = nn.Transformer.generate_square_subsequent_mask(T).to(tgt.device)\n","        output = self.transformer_decoder(tgt_emb, memory, tgt_mask=tgt_mask)\n","        output = self.fc_out(output)\n","        return output\n","\n","# Combine Encoder and Decoder into one Model\n","class HandwrittenMathToLatexModel(nn.Module):\n","    def __init__(self, vocab_size, d_model=256):\n","        super(HandwrittenMathToLatexModel, self).__init__()\n","        self.encoder = TransformerEncoder(d_model=d_model)\n","        self.decoder = TransformerDecoder(vocab_size=vocab_size, d_model=d_model)\n","\n","    def forward(self, images, tgt_seq):\n","        # images: [B, 1, H, W]\n","        # tgt_seq: [T, B]\n","        memory = self.encoder(images)  # Already in shape [S, B, E]\n","        output = self.decoder(tgt_seq, memory)  # [T, B, vocab_size]\n","        return output\n","\n","# Training Loop\n","def train(model, dataloader, criterion, optimizer, device):\n","    model.train()\n","    running_loss = 0.0\n","    for images, target_seq in dataloader:\n","        images = images.to(device)\n","        # Get the tensor from the tuple returned by string_to_tensor\n","        target_seq = string_to_tensor(target_seq, vocab).to(device)\n","        target_seq = target_seq.to(device)\n","        # Assume target_seq is size [T, B]\n","        optimizer.zero_grad()\n","        # Shift target sequence for teacher forcing\n","        input_seq = target_seq[:-1, :]\n","        output = model(images, input_seq)\n","        # Compute loss between output and target_seq[1:,:]\n","        loss = criterion(output.reshape(-1, output.shape[-1]), target_seq[1:, :].reshape(-1))\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","    return running_loss / len(dataloader)\n","\n","def test(model, dataloader, criterion, device):\n","    model.eval()\n","    running_loss = 0.0\n","    with torch.no_grad():\n","        for images, target_seq in dataloader:\n","            images = images.to(device)\n","            target_seq = string_to_tensor(target_seq, vocab).to(device)\n","            # Shift target sequence for decoder input (same as in training)\n","            input_seq = target_seq[:-1, :]\n","            output = model(images, input_seq)\n","\n","            # _, predicted_indices = torch.max(output, dim=2)\n","            # predicted_text = tensor_to_string(predicted_indices, vocab)\n","            # print(f\"Predicted: {predicted_text}\")\n","\n","            # Calculate loss against the full target sequence (offset by 1)\n","            loss = criterion(output.reshape(-1, output.shape[-1]),\n","                            target_seq[1:, :].reshape(-1))\n","            running_loss += loss.item()\n","    return running_loss / len(dataloader)\n","\n","\n","# Initialize Hyperparameters\n","batch_size = 16\n","learning_rate = 1e-3\n","num_epochs = 10\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = HandwrittenMathToLatexModel(vocab_size=vocab_size).to(device)\n","criterion = nn.CrossEntropyLoss(ignore_index=0)  # Adjust ignore_index if needed (for padding)\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","for epoch in range(num_epochs):\n","    train_loss = train(model, train_loader, criterion, optimizer, device)\n","    test_loss = test(model, test_loader, criterion, device)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G9gD42LTQ-Le","executionInfo":{"status":"ok","timestamp":1744251160838,"user_tz":300,"elapsed":1854008,"user":{"displayName":"Ajitesh Parthasarathy","userId":"10718185110510952821"}},"outputId":"2de7cfaa-dcc4-4128-bac2-73ed10e06d77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 2.9391, Test Loss: 2.5367\n","Epoch [2/10], Train Loss: 2.4199, Test Loss: 2.2440\n","Epoch [3/10], Train Loss: 2.1816, Test Loss: 2.0670\n","Epoch [4/10], Train Loss: 2.0129, Test Loss: 1.9482\n","Epoch [5/10], Train Loss: 1.9048, Test Loss: 1.8924\n","Epoch [6/10], Train Loss: 1.8280, Test Loss: 1.8456\n","Epoch [7/10], Train Loss: 1.7559, Test Loss: 1.8052\n","Epoch [8/10], Train Loss: 1.6816, Test Loss: 1.7902\n","Epoch [9/10], Train Loss: 1.6341, Test Loss: 1.7596\n","Epoch [10/10], Train Loss: 1.5769, Test Loss: 1.7520\n"]}]},{"cell_type":"markdown","source":["**Potential Model Evaluation Method** (from https://github.com/google-research/google-research/blob/master/mathwriting/mathwriting_code_examples.ipynb)"],"metadata":{"id":"lJPbIDhILlK4"}},{"cell_type":"code","source":["import re\n","\n","_COMMAND_RE = re.compile(r'\\\\mathbb\\{[a-zA-Z]\\}|\\\\begin\\{[a-z]+\\}|\\\\end\\{[a-z]+\\}|\\\\operatorname\\*?|[a-zA-Z]+|.')\n","\n","def tokenize_expression(s: str) -> list[str]:\n","  \"\"\"Transform a Latex math string into a list of tokens.\"\"\"\n","  tokens = []\n","  while s:\n","    if s[0] == '\\\\':\n","      tokens.append(_COMMAND_RE.match(s).group(0))\n","    else:\n","      tokens.append(s[0])\n","    s = s[len(tokens[-1]) :]\n","  return tokens\n","\n","# Example Usage\n","print(tokenize_expression(r'\\frac{\\alpha}{2} \\not\\in\\mathbb{R}'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wY3lNQjSLqHe","executionInfo":{"status":"ok","timestamp":1743975786895,"user_tz":300,"elapsed":14,"user":{"displayName":"Ajitesh Parthasarathy","userId":"10718185110510952821"}},"outputId":"ace82344-0183-466d-dd7f-8604bf669d0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['\\\\', 'f', 'r', 'a', 'c', '{', '\\\\', 'a', 'l', 'p', 'h', 'a', '}', '{', '2', '}', ' ', '\\\\', 'n', 'o', 't', '\\\\', 'i', 'n', '\\\\mathbb{R}']\n"]}]},{"cell_type":"code","source":["import jiwer\n","\n","class TokenizeTransform(jiwer.transforms.AbstractTransform):\n","    def process_string(self, s: str):\n","      return tokenize_expression(r'{}'.format(s))\n","    def process_list(self, tokens: list[str]):\n","      return [self.process_string(token) for token in tokens]\n","\n","def compute_cer(truth_and_output: list[tuple[str, str]]):\n","  \"\"\"Computes CER given pairs of ground truth and model output.\"\"\"\n","  ground_truth, model_output = zip(*truth_and_output)\n","  return jiwer.cer(truth=list(ground_truth),\n","            hypothesis=list(model_output),\n","            reference_transform=TokenizeTransform(),\n","            hypothesis_transform=TokenizeTransform(),\n","      )\n","\n","# Test data to run compute_cer().\n","# The first element is the model prediction, the second the ground truth.\n","examples = [\n","    (r'\\sqrt{2}', r'\\sqrt{2}'),  # 0 mistakes, 4 tokens\n","    (r'\\frac{1}{2}', r'\\frac{i}{2}'),  # 1 mistake, 7 tokens\n","    (r'\\alpha^{2}', 'a^{2}'),  # 1 mistake, 5 tokens\n","    ('abc', 'def'),  # 3 mistakes, 3 tokens\n","]\n","\n","# 5 mistakes for 19 tokens: 26.3% error rate.\n","print(f\"{compute_cer(examples)*100:.1f} %\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1OS81JAYL-Ji","executionInfo":{"status":"ok","timestamp":1743975790850,"user_tz":300,"elapsed":21,"user":{"displayName":"Ajitesh Parthasarathy","userId":"10718185110510952821"}},"outputId":"a19c854d-2e23-43fb-8b6e-0f05ed5504da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["28.1 %\n"]}]},{"cell_type":"markdown","source":["Step 2.) Finetune an LLM using GRPO training to correct errors in the Latex syntax"],"metadata":{"id":"7Pbke9dinI73"}},{"cell_type":"code","source":["from trl import GRPOConfig, GRPOTrainer\n","from datasets import Dataset\n","\n","# Turn the Pandas df from step 1 into a Dataset object\n","dataset = Dataset.from_pandas(df)\n","\n","# Create the prompts for GRPO Training\n","def create_prompt(example):\n","    example[\"prompt\"] = f\"\"\"Please ensure that the following text is valid LaTeX by fixing syntax issues as needed. Here is the potentially invalid LaTeX: {example[\"predicted_latex\"]}. What is the fixed valid LaTeX: \"\"\"\n","    return example\n","\n","dataset = dataset.map(create_prompt)\n","print(dataset)\n","\n","# Determine device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Training will run on: {device}\")\n","\n","# Create a unique checkpoint directory for each run using a timestamp\n","run = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n","checkpoint_dir = f'/users/0/brogn002/{run}'\n","os.makedirs(checkpoint_dir, exist_ok=True)\n","\n","def reward(completions, **kwargs):\n","    \"\"\"Reward function that rewards a similarity score between two strings in the range [0,1].\"\"\"\n","    correct_latex = kwargs[\"label\"]\n","    rewards = []\n","    for completion, reference in zip(completions, correct_latex):\n","      if not completion or not reference:\n","        rewards.append(0.0)\n","        continue\n","      # Do not reward empty strings\n","      if len(completion) == 0:\n","            rewards.append(0.0)\n","            continue\n","      # Perfect match gets a full reward\n","      if completion == reference:\n","          rewards.append(1.0)\n","          continue\n","      # Apply RapidFuzz ratio for all cases (handles different lengths well)\n","      similarity = fuzz.ratio(completion, reference) / 100.0\n","      # Add additional penalty for length mismatch\n","      length_penalty = max(0, 1 - (abs(len(completion) - len(reference)) / max(len(reference), 1)))\n","      # Combined score is a linear combination of similarity and length_penalty\n","      final_score = (similarity * 0.5) + (length_penalty * 0.5)\n","      rewards.append(final_score)\n","    return rewards\n","\n","training_args = GRPOConfig(\n","    output_dir=checkpoint_dir,\n","    logging_steps=50,\n","    per_device_train_batch_size=4,  # Decrease this to lower vram usage\n","    num_generations=4,  # Decrease this to lower vram usage\n","    save_strategy=\"no\",  # Do not save checkpoints (saves storage space)\n","    bf16=True,  # Enable bf16 mixed precision on A100 GPUs\n",")\n","\n","trainer = GRPOTrainer(\n","    model=\"microsoft/Phi-4-mini-instruct\",\n","    reward_funcs=reward,\n","    args=training_args,\n","    train_dataset=dataset,\n",")\n","\n","trainer.train()"],"metadata":{"id":"7KYLcJSvnJKI"},"execution_count":null,"outputs":[]}]}